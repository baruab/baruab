# -*- coding: utf-8 -*-
"""DATA_698_Graph_temporal.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/150EboMj4CwXBQ2w5SP_j39z9m7baXjxk

Construct multiple views of graph
"""

#!pip uninstall pandas
#!pip show pandas
#!pip install pandas==1.3.5

#!pip install --upgrade pandas
!pip install google-colab geopandas plotnine statsmodels xarray
!pip install pandas google-colab geopandas plotnine statsmodels xarray

"""# Load the dataset"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
#to ignore warnings
import warnings
warnings.filterwarnings('ignore')

## In the interest of saving time, calling the API multiple times, as the information is of static nature
##   the generated file with added columns is saved and read directly to save compute time

access_log_location_url = 'https://raw.githubusercontent.com/baruab/baruab/refs/heads/main/DATA_698/tokenized_access_logs_global.csv'
df_ac_log = pd.read_csv(access_log_location_url)

print("Pandas version:", pd.__version__)

# Drop uplicates
df_ac_log = df_ac_log.drop_duplicates()

"""# Adding Features to the data"""

df_ac_log['Dt'] = df_ac_log['Date'].str.split(' ').str[0]

# Convert the 'date' column to datetime
df_ac_log['date'] = pd.to_datetime(df_ac_log['Dt'])

# Extract the day of the week
df_ac_log['day_of_week'] = df_ac_log['date'].dt.day_name()
df_ac_log['weekday'] = df_ac_log['date'].dt.weekday

df_ac_log["AddToCart"] = df_ac_log["url"].str.contains("add_to_cart").astype(int) # str.extract("(add_to_cart)")
#df_ac_log.head()

# Reassign the IP address to IDs (make it easier later for creating edges)

ipaddrs = df_ac_log['ip'].unique()
new_ip_ids = list(range(len(df_ac_log['ip'].unique())))
map_ip = dict(zip(ipaddrs, new_ip_ids))
print(type(map_ip))

df_ac_log['ip_id'] = df_ac_log['ip'].map(map_ip)

print(len(ipaddrs))
#df_ac_log.head()

# Reassign the Product to IDs (make it easier later for creating edges)

products = df_ac_log['Product'].unique()
new_prod_ids = list(range(len(df_ac_log['Product'].unique())))
map_prod = dict(zip(products, new_prod_ids))
print(type(map_prod))

df_ac_log['Product_Id'] = df_ac_log['Product'].map(map_prod)

#### Category
# Reassign the Category to IDs

cats = df_ac_log['Category'].unique()
new_cat_ids = list(range(len(df_ac_log['Category'].unique())))
map_cat = dict(zip(cats, new_cat_ids))

df_ac_log['Category_Id'] = df_ac_log['Category'].map(map_cat)

# Reassign the Dept to IDs

depts = df_ac_log['Department'].unique()
new_dept_ids = list(range(len(df_ac_log['Department'].unique())))
map_dept = dict(zip(depts, new_dept_ids))

df_ac_log['Department_Id'] = df_ac_log['Department'].map(map_dept)

#mapping = {index: i for i, index in enumerate(df_ac_cat_subset.index.unique())}

"""**Split the date time string into date & time represented as numbers**"""

df_ac_log['date_id'] = df_ac_log['Date'].str.split('/').str[1]
df_ac_log['month_id'] = df_ac_log['Date'].str.split('/').str[0]
df_ac_log['year_id'] = df_ac_log['Date'].str.split('/').str[2].str.split(' ').str[0]

df_ac_log['time'] = df_ac_log['Date'].str.split(' ').str[1]


df_ac_log['Dt'] = df_ac_log['Date'].str.split(' ').str[0]

# Convert the 'date' column to datetime
df_ac_log['date'] = pd.to_datetime(df_ac_log['Dt'])

# Extract the day of the week
df_ac_log['day_of_week'] = df_ac_log['date'].dt.day_name()
df_ac_log['weekday'] = df_ac_log['date'].dt.weekday

# Convert 'numbers' column to integer
df_ac_log['date_id'] = df_ac_log['date_id'].astype(int)
df_ac_log['month_id'] = df_ac_log['month_id'].astype(int)
df_ac_log['year_id'] = df_ac_log['year_id'].astype(int)

# group date into week ids in df_session_log
df_ac_log['week_id'] = df_ac_log['date'].dt.isocalendar().week

# create year_month_id based on year_id and month_id
df_ac_log['year_month_id'] = df_ac_log['year_id'].astype(int)*100 + df_ac_log['month_id'].astype(int)

# Reassign the year_month_id to snapshot_ID (make it easier later for splitting graphs)

year_months = df_ac_log['year_month_id'].unique()
new_year_months = list(range(len(df_ac_log['year_month_id'].unique())))
map_snapshot = dict(zip(year_months, new_year_months))
print(type(map_snapshot))

df_ac_log['snapshot_id'] = df_ac_log['year_month_id'].map(map_snapshot)

# Merge date and ip columns to create new column in df_ac_log
df_ac_log['date_ip_id'] = df_ac_log['date'].astype(str) + '_' + df_ac_log['ip_id'].astype(str)

access_count = df_ac_log.groupby("ip_id")["date_id"].count().rename("access_count")
print(access_count)

"""Create Encoders"""

!pip install sentence-transformers

#install torch
!pip install torch

import torch
from sentence_transformers import SentenceTransformer

class SequenceEncoder:
     def __init__(self, model_name='all-MiniLM-L6-v2', device=None):
         self.device = device
         self.model = SentenceTransformer(model_name, device=device)

     @torch.no_grad()
     def __call__(self, df):
         x = self.model.encode(df.values, show_progress_bar=True,
                               convert_to_tensor=True, device=self.device)
         return x.cpu()

encoder = SequenceEncoder() # Create an instance of the SequenceEncoder class

# subset the dataframe
df_cat = df_ac_log[['Category']]
df_cat = df_cat.drop_duplicates()
print(df_cat.shape)


category_xs = [encoder(df_cat['Category'])] # Encode the 'Category' column
category_x = torch.cat(category_xs, dim=-1) # Concatenate the encoded results
print(category_x.shape)

# subset the dataframe
df_prod = df_ac_log[['Product']]
df_prod = df_prod.drop_duplicates()
print(df_prod.shape)

product_xs = [encoder(df_prod['Product'])] # Encode the 'Category' column
product_x = torch.cat(product_xs, dim=-1) # Concatenate the encoded results
print(product_x.shape)
print(product_x)

print(category_x)
print(category_x.shape)

"""**Alternate Label encoder**"""

from sklearn.preprocessing import LabelEncoder

# Label encode the 'Category' column
label_encoder = LabelEncoder()

# get unique category names
category_labels = label_encoder.fit_transform(df_ac_log['Category'].unique())
#print(category_labels)
print(len(category_labels))
category_labels_tensor = torch.tensor(category_labels, dtype=torch.long).view(-1, 1)
print(category_labels_tensor)

"""# Define the node features"""

#Let's create the User Node, create a subset dataframe.
# Add user city, access count and buy intent count

access_count = df_ac_log.groupby("ip_id")["ip_id"].count().rename("access_count")
buy_count = df_ac_log[df_ac_log["AddToCart"] == 1].groupby("ip_id")["AddToCart"].count().rename("buy_count")
user_node_features = pd.concat([access_count, buy_count], axis=1)

# Remap user ID
user_node_features = user_node_features.reset_index(drop=False)
user_node_features.head()
user_id_mapping = user_node_features['ip_id']

# Only keep user features
#user_node_features = user_node_features.drop('ip_id', axis=1)
user_node_features.head()


df_ip_city = df_ac_log[['ip_id', 'City', 'State', 'Country']]
df_ip_city = df_ip_city.drop_duplicates()
df_ip_city.head()

# merge user_node_features and df_ip_city by ip_id
df_user_features = pd.merge(user_node_features, df_ip_city, on='ip_id')
df_user_features = df_user_features.drop_duplicates()

# Only keep user features
#df_user_features = df_user_features.drop('ip_id', axis=1)
#df_user_features.head()
print(df_user_features.shape)

# torch cat the features
#torch access_count
access_cnt = df_user_features['access_count']
access_cnt = torch.tensor(access_cnt, dtype=torch.float).view(-1, 1)
print(access_cnt.shape)

#torch city
df_user_features['City'] = df_user_features['City'].astype(str) # Convert cities to a list of strings
df_user_features['State'] = df_user_features['State'].astype(str) # Convert cities to a list of strings

# torch cities
city_xs =  [encoder(df_user_features['City'])]
city_x = torch.cat(city_xs, dim=-1) # Concatenate the encoded results
print(city_x.shape)

# torch states
state_xs =  [encoder(df_user_features['State'])]
state_x = torch.cat(state_xs, dim=-1) # Concatenate the encoded results
print(state_x.shape)

user_features = torch.cat([city_x, state_x], dim=1)
print(user_features.shape)

"""Create Product features"""

# get unique department names

df_product_depts = df_ac_log[['Product_Id', 'Department_Id']]
df_product_depts = df_product_depts.drop_duplicates()
df_product_depts.head()

# convert x into tensor
product_features = torch.tensor(df_product_depts['Product_Id'], dtype=torch.float).view(-1,1)
print(product_features.shape)

#dept_labels = label_encoder.fit_transform(df_product_depts['Department_Id'])

dept_labels = df_product_depts['Department_Id']
#print(dept_labels)
#print(len(dept_labels))

dept_labels_tensor = torch.tensor(dept_labels, dtype=torch.float).view(-1, 1)
product_y = dept_labels_tensor

#print(product_y)
print(product_y.shape)

!pip install torch-geometric torch-sparse torch-scatter

# Import the necessary library
from torch_geometric.data import HeteroData

user_ids = torch.tensor(df_user_features['ip_id'].values, dtype=torch.long)
user_y = torch.tensor(df_user_features['buy_count'].values, dtype=torch.long).view(-1,1)

hdata = HeteroData()
hdata.snapshot_id = torch.tensor(df_ac_log['snapshot_id'].unique(), dtype=torch.long)
hdata.year_month_id = torch.tensor(df_ac_log['year_month_id'].unique(), dtype=torch.long)
hdata.week_id = torch.tensor(df_ac_log['week_id'].unique(), dtype=torch.long)

hdata['user'].num_nodes = len(user_node_features)
hdata['user'].x = city_x
hdata['user'].ids = user_ids
hdata['user'].y = user_y   # buy_count

product_ids = torch.tensor(df_product_depts['Product_Id'].values, dtype=torch.long)
hdata['product'].num_nodes = len(df_product_depts)
hdata['product'].x = product_x
hdata['product'].ids = product_ids
hdata['product'].y = product_y   # dept label

print(hdata)
print(hdata.snapshot_id)
print(hdata.year_month_id)
print(hdata.week_id)

"""# Create Temporal Datasets"""

from google.colab import files
uploaded = files.upload()  # Upload the file from your local machine

!mv tsagcn.py /usr/local/lib/python3.10/dist-packages/torch_geometric_temporal/nn/attention

#######
#create a two dimensional array

!pip install torch-geometric-temporal

import pandas as pd
import torch
import torch_geometric
#import torch_geometric_temporal

print("Pandas version:", pd.__version__)
print("Torch version:", torch.__version__)
print("PyTorch Geometric version:", torch_geometric.__version__)
#print("PyTorch Geometric Temporal version:", torch_geometric_temporal.__version__)

#from google.colab import files
#uploaded = files.upload()  # Upload the file from your local machine

#!mv tsagcn.py /usr/local/lib/python3.10/dist-packages/torch_geometric_temporal/nn/attention

import torch # Import the torch module
from datetime import datetime # Import the datetime module from the datetime library

# Seperate by buy vs view using AddToCart flag
buy_edge_index=[]
buy_timestamp=[]

#Iterate the dataframe
for index, row in df_ac_log.iterrows():

  timestamp = datetime.strptime(row["Date"],'%m/%d/%Y %H:%M')
  ts_unix = int(timestamp.timestamp())
  buy_edge_index.append([row["ip_id"], row["Product_Id"]])
  buy_timestamp.append(ts_unix)

# Convert to tensor and add to HeteroData
buy_edge_index = torch.tensor(buy_edge_index, dtype=torch.long).t().contiguous()
buy_timestamp = torch.tensor(buy_timestamp, dtype=torch.long).view(-1, 1)
hdata['user', 'buy', 'product'].edge_index = buy_edge_index
### add edge_type attribute
hdata['user', 'buy', 'product'].edge_type = 'buy'
hdata['user', 'buy', 'product'].edge_time = buy_timestamp

# torch AddToCart from df_ac_log
add_to_cart_labels = torch.tensor(df_ac_log['AddToCart'].values, dtype=torch.long)
hdata['user', 'buy', 'product'].edge_label = add_to_cart_labels


# Add reverse relation edge index for 'product' -> 'user'
hdata['product', 'rev_buy', 'user'].edge_index = hdata['user', 'buy', 'product'].edge_index.flip(0)

# Optionally, add edge attributes for the reverse relation
# If `edge_attr` is present for 'buys' edges, you can reuse it for 'rev_buys'
if 'edge_attr' in hdata['user', 'buy', 'product']:
    hdata['product', 'rev_buy', 'user'].edge_attr = hdata['user', 'buy', 'product'].edge_attr

print(hdata)
print(buy_edge_index)
print(buy_edge_index.shape)

print(hdata)
print(buy_edge_index)
print(buy_edge_index.shape)

"""Prepare temporal snapshots"""

# Split the dataframe by session id, date and ip address simulating temporal behaviour of the users on the website

""" DON'T DELETE will uncomment later  """
def split_dataframe_by_column(df, column_name):
    dataframes = []
    for value in df[column_name].unique():
        dataframes.append(df[df[column_name] == value])
    return dataframes

split_dfs = split_dataframe_by_column(df_ac_log, 'date_ip_id')
print(len(split_dfs))

print(split_dfs[0]['date_id'])

print(split_dfs[0].info())

# get unique department names

df_product_depts = df_ac_log[['Product_Id', 'Department_Id']]
df_product_depts = df_product_depts.drop_duplicates()
df_product_depts.head()

# convert x into tensor
product_features = torch.tensor(df_product_depts['Product_Id'], dtype=torch.float).view(-1,1)
print(product_features.shape)

#dept_labels = label_encoder.fit_transform(df_product_depts['Department_Id'])

dept_labels = df_product_depts['Department_Id']
#print(dept_labels)
#print(len(dept_labels))

dept_labels_tensor = torch.tensor(dept_labels, dtype=torch.float).view(-1, 1)
product_y = dept_labels_tensor

#print(product_y)
print(product_y.shape)

"""# Create DynamicGraphTemporalSignal object"""

# Initialize buy_edge_index as an empty list outside the loop
edge_index = []
session_hdata_list = []

node_features=[]
edge_indices=[]
edge_weights=[]
edge_labels=[]
labels=[]

# Iterate the Split_df list
#for i in range(len(split_dfs)):
#  46556 max number of sessions

for i in range(1,5000):
  edge_index = []
  temp_weights=[]
  temp_labels=[]

  split_dfs[i] = split_dfs[i].sort_values(by='time')
  # Convert 'time' column to datetime objects
  split_dfs[i]['time'] = pd.to_datetime(split_dfs[i]['time'])
  split_dfs[i]['avg_req_duration'] = (max(split_dfs[i]['time']) - min(split_dfs[i]['time'])) / len(split_dfs[i])
  split_dfs[i]['num_requests'] = len(split_dfs[i])
  # num buys based on AddToCart
  split_dfs[i]['num_buys'] = split_dfs[i]['AddToCart'].sum()
  # num views is num_requests minus num_buys
  split_dfs[i]['num_views'] = split_dfs[i]['num_requests'] - split_dfs[i]['num_buys']

  split_dfs[i]['exit_product_id'] = split_dfs[i]['Product_Id'].tail(1).values[0]
  split_dfs[i]['exit_buy'] = split_dfs[i]['AddToCart'].tail(1).values[0]
  split_dfs[i]['entry_product_id'] = split_dfs[i]['Product_Id'].head(1).values[0]
  split_dfs[i]['entry_buy'] = split_dfs[i]['AddToCart'].head(1).values[0]

  #### Let's start with the Product Node, create a subset dataframe.
  # It will have Product_Id, Category, Department, url
  df_temp_product_nodes = split_dfs[i][['Product_Id', 'Category']]
  df_temp_product_nodes = df_temp_product_nodes.drop_duplicates()
  df_temp_product_nodes = df_temp_product_nodes.reset_index(drop=True)
  #print("!!! df_temp_product_nodes !!!")
  #print(df_temp_product_nodes)

  # Filter df_product_features by Product_Id
  df_temp_product_features = df_product_depts[df_product_depts['Product_Id'].isin(df_temp_product_nodes['Product_Id'])]
  #print(df_temp_product_features)

  # Create the user node and features
  df_temp_user_node = split_dfs[i][['date_ip_id']]
  df_temp_user_node = df_temp_user_node.drop_duplicates()
  df_temp_user_node = df_temp_user_node.reset_index(drop=True)
  # print("!!!! df_temp_user_node !!!")
  # print(df_temp_user_node)


  avg_req_duration = split_dfs[i]['avg_req_duration'].mean()
  num_requests = split_dfs[i]['num_requests'].mean()
  num_buys = split_dfs[i]['num_buys'].mean()
  num_views = split_dfs[i]['num_views'].mean()

  exit_product_id = split_dfs[i]['exit_product_id'].mean()

  # Convert avg_req_duration to a numeric representation before concatenation
  avg_req_duration_seconds = avg_req_duration.total_seconds()

  # Create a DataFrame from the individual features
  df_temp_user_features = pd.DataFrame({
    'avg_req_duration': [avg_req_duration_seconds],
    'num_requests': [num_requests],
    'num_buys': [num_buys],
    'num_views': [num_views],
    'exit_product_id': [exit_product_id]
  })
  #print("!!!! df_temp_user_features !!!")
  #print(df_temp_user_features)


  num_edges = len(split_dfs[i])
  for j in range(num_edges):
    edge_index.append([split_dfs[i]["ip_id"].iloc[j], split_dfs[i]["Product_Id"].iloc[j]]) # Access element by index j
    temp_weights.append([split_dfs[i]["AddToCart"].iloc[j]])

  temp_labels.append(split_dfs[i]['num_buys'].mean())
  print("temp_labels = ", temp_labels)
  temp_edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()
  print("edge_index =", temp_edge_index)
  print("edge_index shape =", temp_edge_index.shape)


  ##### Build the dataset
  temp_data = HeteroData()

  # Set the number of nodes for 'user' and 'product'
  temp_data.date_id = split_dfs[i]['date_id'].unique() # df_temp_user_node['ip_id']
  temp_data['user'].num_nodes = len(df_temp_user_features) # Assuming user_node_features is a list or array of user features
  temp_data['user'].id = split_dfs[i]['ip_id'].unique() # df_temp_user_node['ip_id']
  temp_data['user'].session_id = split_dfs[i]['date_ip_id'].unique() # df_temp_user_node['ip_id']
  temp_data['user'].x = df_temp_user_features
  temp_data['user'].y = temp_labels


  temp_data['product'].x = df_temp_product_features
  temp_data['product'].id = split_dfs[i]['Product_Id'].unique()
  temp_data['product'].num_nodes = len(df_temp_product_features) # Assuming df_product_features is a DataFrame or array of product features
  temp_data['user', 'buy', 'product'].edge_index = temp_edge_index
  temp_data['user', 'buy', 'product'].edge_type = 'buy'
  temp_data['user', 'buy', 'product'].edge_label = num_buys
  temp_data['product', 'rev_buy', 'user'].edge_index = temp_edge_index.flip(0)
  temp_data['product', 'rev_buy', 'user'].edge_label = num_buys

  session_hdata_list.append(temp_data)

  print("~~~ num edges ~~~ ", num_edges)
  print("~~~ tempdata ~~~ ", i)
  #print(temp_data)

  node_features.append({
      'user': temp_data['user'].x,
      'product': temp_data['product'].x
  })
  print(" temp_data['user'].x.shape = ", temp_data['user'].x.shape)
  print(" temp_data['product'].x.shape = ", temp_data['product'].x.shape)

  edge_indices.append(temp_edge_index)
  temp_edge_weight = torch.tensor(temp_weights, dtype=torch.float).reshape(-1)
  edge_weights.append(temp_edge_weight)
  print("edge_weights shape = " , temp_edge_weight.shape)

  edge_labels.append({
      ('user', 'buy', 'product'): temp_data[('user', 'buy', 'product')].edge_label,
      ('product', 'rev_buy', 'user'): temp_data[('product', 'rev_buy', 'user')].edge_label
  })
  label = torch.tensor(temp_data['user'].y, dtype=torch.float).reshape(-1)
  labels.append(label)
  labels = [torch.tensor([label], dtype=torch.float) for label in labels]  # Convert each label to a tensor
  print("labels/target = ", label)
  print("labels/target shape = ", label.shape)

  print("~~~~ ", i)
#print(node_features)

# Concatenate user and product features into a single tensor for each snapshot
node_features_list = []
for snapshot_features in node_features:
    user_features = snapshot_features['user']  # Assuming 'user' key exists
    product_features = snapshot_features['product']  # Assuming 'product' key exists

    # Convert to tensors if necessary
    user_features_tensor = torch.tensor(user_features.values, dtype=torch.float) if isinstance(user_features, pd.DataFrame) else torch.tensor(user_features, dtype=torch.float)
    product_features_tensor = torch.tensor(product_features.values, dtype=torch.float) if isinstance(product_features, pd.DataFrame) else torch.tensor(product_features, dtype=torch.float)


    # If either user or product features have two dimensions, reshape to one dimension.
    user_features_tensor = user_features_tensor.reshape(-1) if user_features_tensor.dim() == 2 else user_features_tensor
    product_features_tensor = product_features_tensor.reshape(-1) if product_features_tensor.dim() == 2 else product_features_tensor

    # Concatenate user and product features
    all_features = torch.cat([user_features_tensor, product_features_tensor])

    node_features_list.append(all_features)

from google.colab import files
uploaded = files.upload()  # Upload the file from your local machine

!mv tsagcn.py /usr/local/lib/python3.10/dist-packages/torch_geometric_temporal/nn/attention

#!pip install torch_geometric_temporal
import numpy as np
import torch
from torch_geometric_temporal.signal import temporal_signal_split, DynamicGraphTemporalSignal
import pandas as pd

edge_labels_tensors = []
for edge_label_dict in edge_labels:
    # Extract edge labels for ('user', 'buy', 'product') relation
    edge_label = edge_label_dict[('user', 'buy', 'product')]
    # Convert to tensor and append
    edge_labels_tensors.append(torch.tensor([edge_label], dtype=torch.float))



# Modify the _get_additional_feature method
def _get_additional_feature(self, time_index, feature_key):
    feature = getattr(self, feature_key)[time_index]
    # Check if feature is a PyTorch tensor
    if isinstance(feature, torch.Tensor):
        # If it's a tensor, get the dtype kind using 'kind' attribute if available,
        # otherwise, use the dtype name directly.
        dtype_kind = feature.dtype.kind if hasattr(feature.dtype, 'kind') else feature.dtype
    else:
        # If it's not a tensor, get the dtype kind as before
        dtype_kind = feature.dtype.kind

    if dtype_kind == "i" or dtype_kind == torch.int64:  # Handle both cases
        return torch.LongTensor(feature)
    elif dtype_kind == "f" or dtype_kind == torch.float32: # Handle both cases
        return torch.FloatTensor(feature)
    else:  # Handle other dtypes or raise an exception
        return feature  # Or raise an exception if needed


# Apply the monkey patch to DynamicGraphTemporalSignal
DynamicGraphTemporalSignal._get_additional_feature = _get_additional_feature


# Ensure node_features_list and labels have the same length
# This is a critical step to fix the "Temporal dimension inconsistency" error
min_len = min(len(node_features_list), len(labels))
node_features_list = node_features_list[:min_len]
edge_indices = edge_indices[:min_len]  # Add this line to truncate edge_indices as well
edge_weights = edge_weights[:min_len]  # Add this line to truncate edge_weights as well
edge_labels_tensors = edge_labels_tensors[:min_len]  # Add this line to truncate edge_labels_tensors as well
labels = labels[:min_len]


temporal_data = DynamicGraphTemporalSignal(
    edge_indices=edge_indices,
    edge_weights=edge_weights,
    edge_features=edge_labels_tensors,
    features=node_features_list,
    targets=labels
)

# Split into train and test datasets
train_dataset, test_dataset = temporal_signal_split(temporal_data, train_ratio=0.8)

# Convert targets to a NumPy array
train_dataset.targets = [np.array(target) for target in train_dataset.targets]

# Ensure targets are NumPy arrays
train_dataset.targets = [np.array(target) for target in train_dataset.targets]
test_dataset.targets = [np.array(target) for target in test_dataset.targets]

"""
# Check for empty edge indices in the train dataset and handle them
train_dataset_filtered = []
for snapshot in train_dataset:
    # Check if edge_index is empty by checking its dimension
    # If it has 2 dimensions and the second dimension is greater than 0, it's not empty
    if snapshot.edge_index.dim() == 2 and snapshot.edge_index.size(1) > 0:
        train_dataset_filtered.append(snapshot)
    else:
        print("Warning: Skipping snapshot with empty edge index.")

train_dataset = train_dataset_filtered  # Replace the original dataset
"""

print(train_dataset)
print(type(train_dataset))


print(f"Edge Indices: {[ei.shape for ei in edge_indices]}")
#print(f"Edge Weights: {[ew.shape for ew in edge_weights]}")
print(f"Edge Features: {[ef.shape for ef in edge_labels_tensors]}")
print(f"Node Features: {[nf.shape for nf in node_features_list]}")
print(f"Targets: {[t.shape for t in labels]}")


# Now iterate over snapshots
for snapshot in train_dataset:
    x_t = snapshot.x
    edge_index_t = snapshot.edge_index  # Edge indices at time t
    y_t = snapshot.y  # Targets at time t

    # Check if x_t is a tensor, and if so, get its dtype kind
    feature_kind = 'f' if x_t.dtype.is_floating_point else 'i' if x_t.dtype.is_complex else None

    # Print the shape with the feature kind if it's a tensor
    # print(f"Features: {x_t.shape}, Edge Indices: {edge_index_t.shape}, Targets: {y_t.shape}, Feature Kind: {feature_kind}")

"""#  Define Temporal Graph Neural Network (TGN) model

import torch
from torch.nn import Linear, Module
from torch_geometric_temporal.nn.recurrent import GConvGRU

class TemporalGNN(Module):
    def __init__(self, in_channels, hidden_channels, out_channels):
        super(TemporalGNN, self).__init__()
        self.recurrent = GConvGRU(in_channels, hidden_channels, 1)  # in_channels=1
        self.linear = Linear(hidden_channels, out_channels)  # Final classifier

    def forward(self, x, edge_index, edge_weight=None, h=None):
        # Ensure edge_index is within the bounds of the node features
        num_nodes = x.shape[0]
        edge_index = edge_index[:, (edge_index < num_nodes).all(dim=0)]

        # Handle no valid edges
        if edge_index.shape[1] == 0:
            if h is None:
                h = torch.zeros((num_nodes, self.recurrent.out_channels), device=x.device)
            return self.linear(h), h

        # GConvGRU forward pass
        x = x.unsqueeze(0)  # Add batch dimension: (1, num_nodes, in_channels)
        h = self.recurrent(x, edge_index, edge_weight, h)  # Updated hidden state
        h = h.squeeze(0)  # Remove batch dimension: (num_nodes, hidden_channels)

        # Linear layer for output
        out = self.linear(h)  # (num_nodes, out_channels)
        return out, h
"""

import torch
import torch.nn.functional as F  # Import F for relu
from torch.nn import Linear, Module
from torch_geometric_temporal.nn.recurrent import GConvGRU

class RecurrentGCN(torch.nn.Module):
    def __init__(self, node_features):
        super(RecurrentGCN, self).__init__()
        # Changed input features for GConvGRU to 1 to match input data
        self.recurrent = GConvGRU(1, 32, 1)
        self.linear = torch.nn.Linear(32, 1)

    def forward(self, x, edge_index, edge_weight):
        # Reshape x to have 2 dimensions if it only has 1
        if x.dim() == 1:
            x = x.unsqueeze(-1)  # Add a feature dimension

        num_nodes = x.shape[0]
        edge_index = edge_index.clamp(0, num_nodes - 1)

        h = self.recurrent(x, edge_index, edge_weight)
        h = F.relu(h)
        h = self.linear(h)
        return h

# When initializing the model, provide 1 as the node_features to match the input.
model = RecurrentGCN(node_features = 1)

optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

model.train()

for epoch in range(200):
    cost = 0
    for time, snapshot in enumerate(train_dataset):
        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)
        cost = cost + torch.mean((y_hat-snapshot.y)**2)
    cost = cost / (time+1)
    cost.backward()
    optimizer.step()
    optimizer.zero_grad()

model.eval()
cost = 0
for time, snapshot in enumerate(test_dataset):
    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)
    cost = cost + torch.mean((y_hat-snapshot.y)**2)
cost = cost / (time+1)
cost = cost.item()
print("MSE: {:.4f}".format(cost))

model.train()
criterion = torch.nn.MSELoss()

for epoch in range(20):
    total_loss = 0
    snapshot_count = 0  # Initialize a counter for snapshots
    for snapshot in train_dataset:
        # Reshape if necessary
        x = snapshot.x.unsqueeze(-1) if len(snapshot.x.shape) == 1 else snapshot.x
        y = snapshot.y.unsqueeze(-1) if len(snapshot.y.shape) == 1 else snapshot.y

        # Forward pass
        y_hat = model(x, snapshot.edge_index, snapshot.edge_attr)

        # Compute loss
        loss = criterion(y_hat, y)
        total_loss += loss.item()

        # Backward pass and optimization
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        snapshot_count += 1  # Increment the counter for each snapshot

    print(f"Epoch {epoch + 1}, Loss: {total_loss / snapshot_count:.4f}")  # Use snapshot_count instead of len(train_dataset)


# Evaluation
model.eval()
total_loss = 0
snapshot_count =0
with torch.no_grad():
    for snapshot in test_dataset:
        x = snapshot.x.unsqueeze(-1) if len(snapshot.x.shape) == 1 else snapshot.x
        y = snapshot.y.unsqueeze(-1) if len(snapshot.y.shape) == 1 else snapshot.y

        y_hat = model(x, snapshot.edge_index, snapshot.edge_attr)
        loss = criterion(y_hat, y)
        total_loss += loss.item()
        snapshot_count += 1

print(f"Test MSE: {total_loss / snapshot_count:.4f}")

"""Create the training loop"""

# define device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

"""Evaluate the model"""

from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
import torch

def evaluate_model(model, dataset, device):
    model.eval()  # Set the model to evaluation mode
    y_true, y_pred = [], []

    with torch.no_grad():
        for snapshot in dataset:
            x = snapshot.x.to(device)  # Node features
            edge_index = snapshot.edge_index.to(device)  # Edge indices
            y = snapshot.y.to(device)  # Ground truth labels

            # Forward pass to get predictions
            out = model(x, edge_index)
            pred = out.argmax(dim=1)  # Get class predictions

            # Append predictions and true labels for this snapshot
            y_true.append(y.cpu().numpy())
            y_pred.append(pred.cpu().numpy())

    # Flatten arrays for metric computation
    y_true = np.concatenate(y_true)
    y_pred = np.concatenate(y_pred)

    # Compute evaluation metrics
    accuracy = accuracy_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred, average="weighted")
    precision = precision_score(y_true, y_pred, average="weighted")
    recall = recall_score(y_true, y_pred, average="weighted")

    print(f"Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}")
    return accuracy, f1, precision, recall

"""Evaluate using the training dataset and test dataset

Track performance over time
"""

def evaluate_model_per_snapshot(model, dataset, device):
    model.eval()
    snapshot_metrics = []

    with torch.no_grad():
        for idx, snapshot in enumerate(dataset):
            x = snapshot.x.to(device)
            edge_index = snapshot.edge_index.to(device)
            y = snapshot.y.to(device)

            # If your dataset doesn't have edge_weight, create a tensor of ones
            # with the same shape as edge_index to represent uniform edge weights.
            edge_weight = torch.ones(edge_index.shape[1]).to(device)

            out = model(x, edge_index, edge_weight)  # Pass edge_weight to the model

            # Get the indices of the nodes for which you have ground truth labels.
            # Assuming 'y' has a value of -1 for nodes without labels,
            # you can filter these out using a mask.
            labeled_indices = torch.where(y != -1)[0]

            # Select predictions and labels for the labeled nodes only
            out = out[labeled_indices]
            y = y[labeled_indices]

            pred = out.argmax(dim=1)

            # Print shapes for debugging
            print(f"y shape: {y.shape}, pred shape: {pred.shape}")

            # Compute accuracy for this snapshot
            acc = accuracy_score(y.cpu().numpy(), pred.cpu().numpy())
            snapshot_metrics.append(acc)
            print(f"Snapshot {idx + 1} Accuracy: {acc:.4f}")

    return snapshot_metrics

"""Visualize performance over time"""

import matplotlib.pyplot as plt

snapshot_metrics = evaluate_model_per_snapshot(model, test_dataset, device)
plt.plot(range(len(snapshot_metrics)), snapshot_metrics, marker='o')
plt.title("Snapshot-wise Accuracy")
plt.xlabel("Snapshot Index")
plt.ylabel("Accuracy")
plt.show()

"""# Create Train/Validation/Test Splits"""

from sklearn.model_selection import train_test_split

# Split edge indices and labels
edge_indices = hdata['user', 'buy', 'product'].edge_index
labels = hdata['user', 'buy', 'product'].edge_label

# Split indices
train_idx, test_idx = train_test_split(range(edge_indices.size(1)), test_size=0.2, random_state=42)
train_idx, val_idx = train_test_split(train_idx, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2

# Create masks
train_mask = torch.zeros(edge_indices.size(1), dtype=torch.bool)
val_mask = torch.zeros(edge_indices.size(1), dtype=torch.bool)
test_mask = torch.zeros(edge_indices.size(1), dtype=torch.bool)

train_mask[train_idx] = True
val_mask[val_idx] = True
test_mask[test_idx] = True

# Assign masks and split labels
hdata['user', 'buy', 'product'].train_mask = train_mask
hdata['user', 'buy', 'product'].val_mask = val_mask
hdata['user', 'buy', 'product'].test_mask = test_mask

"""Convert into NetworkX graphs"""

from torch_geometric.utils import to_networkx
import matplotlib.pyplot as plt
import networkx as nx

# Extract graph for each timestamp
for t, snapshot in enumerate(train_dataset):  # Assuming train_dataset is temporal
    # Convert snapshot to NetworkX
    g_nx = to_networkx(
        data=snapshot,
        node_attrs=['x'],  # Add desired node attributes for visualization
        edge_attrs=['edge_attr']  # Add desired edge attributes
    )

    # Visualize the graph
    plt.figure(figsize=(10, 7))
    pos = nx.spring_layout(g_nx)  # Compute layout
    nx.draw(
        g_nx, pos, with_labels=True, node_size=500, font_size=10,
        node_color='skyblue', edge_color='gray'
    )
    plt.title(f"Graph at Time Step {t}")
    plt.show()

"""Highlight node and edge types"""

# Example: Heterogeneous visualization with color coding
for t, snapshot in enumerate(train_dataset):
    node_colors = []
    edge_colors = []

    try:
        # Try accessing metadata, if available
        node_types, edge_types = snapshot.metadata()
    except AttributeError:
        # If metadata is not available, provide default behavior or handle it
        print(f"Warning: Metadata not found for snapshot at time step {t}. Using default visualization.")
        # Infer node and edge types if metadata() is not available
        # You might need to adapt this based on your specific data structure
        node_types = list(set(snapshot.x.tolist())) # Assuming node types are encoded in 'x'
        edge_types = list(set(snapshot.edge_attr.tolist())) # Assuming edge types are encoded in 'edge_attr'


        # Assign default colors or handle the lack of metadata accordingly
        node_colors = ['gray'] * len(node_types)  # Default color for all nodes
        edge_colors = ['black'] * len(edge_types)  # Default color for all edges

        # Example: If node types are integers, you might assign colors based on their values
        # node_colors = [plt.cm.get_cmap('viridis')(node_type) for node_type in node_types]


# Example: Heterogeneous visualization with color coding
for t, snapshot in enumerate(train_dataset):
    g_nx = to_networkx(snapshot, to_undirected=True)

    # Get node features and ensure they are iterable
    node_features = snapshot.x.tolist()  # Assuming 'x' contains node features

    # Ensure node_colors has the same length as the number of nodes in the graph
    # and that node features are treated correctly
    node_colors = [
        plt.cm.get_cmap('viridis')(node_feature[0] if isinstance(node_feature, list) else node_feature)  # Handle single float features
        for node_feature in node_features
        if isinstance(node_feature, (list, float))  # Check if node_feature is iterable or a float
    ]

    # If node_colors is shorter than the number of nodes, extend it with a default color
    if len(node_colors) < len(g_nx.nodes):
        node_colors.extend(['gray'] * (len(g_nx.nodes) - len(node_colors)))

    plt.figure(figsize=(10, 7))
    # Generate positions for nodes if 'pos' is not defined in your code
    pos = nx.spring_layout(g_nx)
    nx.draw(
        g_nx, pos, with_labels=True, node_size=500, font_size=10,
        node_color=node_colors, edge_color=edge_colors
    )
    plt.title(f"Heterogeneous Graph at Time Step {t}")
    plt.show()